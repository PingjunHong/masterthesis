{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import accuracy_score, jaccard_score,  confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "def extract_categories(data):\n",
    "    return [entry.get(\"explanation_category\", \"\").strip() for entry in data]\n",
    "\n",
    "def compute_iaa_explanation_category(file1, file2, label_order=None):\n",
    "    print(\"=== Inter-Annotator Agreement: explanation_category ===\\n\")\n",
    "\n",
    "    data1 = read_jsonl(file1)\n",
    "    data2 = read_jsonl(file2)\n",
    "    \n",
    "    # extract category label\n",
    "    labels1 = extract_categories(data1)\n",
    "    labels2 = extract_categories(data2)\n",
    "\n",
    "    print(f\"Total samples: {len(labels1)}\\n\")\n",
    "\n",
    "    # label distribution\n",
    "    print(\"Label distribution:\")\n",
    "    print(\"Annotator 0:\", Counter(labels1))\n",
    "    print(\"Annotator 1:\", Counter(labels2))\n",
    "    print()\n",
    "\n",
    "    all_labels = sorted(set(labels1 + labels2))\n",
    "    if label_order:\n",
    "        labels = label_order\n",
    "    else:\n",
    "        labels = all_labels\n",
    "\n",
    "    # Cohen's Kappa \n",
    "    kappa = cohen_kappa_score(labels1, labels2)\n",
    "    print(f\"Cohen's Kappa: {kappa:.3f}\\n\")\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"Classification Report (Annotator 0 as Ground Truth):\")\n",
    "    print(classification_report(labels1, labels2, labels=labels, target_names=labels, digits=3))\n",
    "\n",
    "    # Top-3 Confusions\n",
    "    print(\"Top-3 Most Frequent Misclassifications:\")\n",
    "    cm = confusion_matrix(labels1, labels2, labels=labels)\n",
    "    confusion_pairs = []\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            if i != j and cm[i][j] > 0:\n",
    "                confusion_pairs.append((cm[i][j], labels[i], labels[j]))\n",
    "    confusion_pairs.sort(reverse=True)\n",
    "    for idx, (count, true_label, pred_label) in enumerate(confusion_pairs[:3]):\n",
    "        print(f\"{idx+1}. {true_label} â†’ {pred_label}: {count} times\")\n",
    "    print()\n",
    "\n",
    "    # Confusion Matrix\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(\n",
    "        ax=ax,\n",
    "        cmap=\"Blues\",\n",
    "        xticks_rotation=35,\n",
    "        colorbar=True\n",
    "    )\n",
    "    plt.setp(ax.get_xticklabels(), rotation=35, ha=\"right\", rotation_mode=\"anchor\", fontsize=18)\n",
    "    plt.setp(ax.get_yticklabels(), rotation=35, ha=\"right\", rotation_mode=\"anchor\", fontsize=18)\n",
    "\n",
    "    for text in disp.text_.ravel():\n",
    "        text.set_fontsize(13)\n",
    "\n",
    "    # ax.set_title(\"Confusion Matrix Between Annotators\", fontsize=16, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Annotator 1\", fontsize=15)\n",
    "    ax.set_ylabel(\"Annotator 0\", fontsize=15)\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "    plt.tight_layout(pad=2.0)\n",
    "    plt.savefig(\"iaa.pdf\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # save disagreed items\n",
    "    disagreed_items = []\n",
    "    for i, (l1, l2) in enumerate(zip(labels1, labels2)):\n",
    "        if l1 != l2:\n",
    "            item = {\n",
    "                \"index\": i,\n",
    "                \"annotator0_label\": l1,\n",
    "                \"annotator1_label\": l2,\n",
    "                \"premise\": data1[i].get(\"premise\", \"\"),\n",
    "                \"hypothesis\": data1[i].get(\"hypothesis\", \"\"),\n",
    "                \"explanation_annotator0\": data1[i].get(\"explanation\", \"\"),\n",
    "                \"explanation_annotator1\": data2[i].get(\"explanation\", \"\"),\n",
    "                \"full_entry_annotator0\": data1[i],\n",
    "                \"full_entry_annotator1\": data2[i]\n",
    "            }\n",
    "            disagreed_items.append(item)\n",
    "\n",
    "    with open(\"disagreed_items.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(disagreed_items, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\nSaved {len(disagreed_items)} disagreed annotation items to disagreed_items.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"classification_iaa/annotator0_iaa.jsonl\"\n",
    "file2 = \"classification_iaa/annotator1_iaa.jsonl\"\n",
    "\n",
    "compute_iaa_explanation_category(file1, file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IAA: highlight overlap analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def parse_indices(s):\n",
    "    if isinstance(s, str):\n",
    "        return sorted([int(i) for i in s.split(\",\") if i.strip().isdigit()])\n",
    "    elif isinstance(s, list):\n",
    "        return sorted([int(i) for i in s])\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def load_jsonl(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "file1 = \"highlight_iaa/annotator0_iaa_highlight.jsonl\"\n",
    "file2 = \"highlight_iaa/annotator1_iaa_highlight.jsonl\"\n",
    "\n",
    "data1 = load_jsonl(file1)\n",
    "data2 = load_jsonl(file2)\n",
    "\n",
    "assert len(data1) == len(data2), f\"File length difference:{len(data1)} vs {len(data2)}\"\n",
    "\n",
    "def compute_iou(set1, set2):\n",
    "    union = set1 | set2\n",
    "    inter = set1 & set2\n",
    "    if not union:\n",
    "        return 1.0\n",
    "    return len(inter) / len(union)\n",
    "\n",
    "inter_annotator_ious = []\n",
    "anno1_gold_ious = []\n",
    "anno2_gold_ious = []\n",
    "\n",
    "for i, (row1, row2) in enumerate(zip(data1, data2)):\n",
    "    # Annotator highlights\n",
    "    a1 = set(parse_indices(row1.get(\"new_highlight1\", \"\")) + parse_indices(row1.get(\"new_highlight2\", \"\")))\n",
    "    a2 = set(parse_indices(row2.get(\"new_highlight1\", \"\")) + parse_indices(row2.get(\"new_highlight2\", \"\")))\n",
    "\n",
    "    # Gold highlights\n",
    "    g1 = set(parse_indices(row1.get(\"sentence1_highlighted\", \"\")))\n",
    "    g2 = set(parse_indices(row1.get(\"sentence2_highlighted\", \"\")))\n",
    "    g_all = g1 | g2\n",
    "\n",
    "    # Inter-annotator IoU\n",
    "    inter_annotator_ious.append(compute_iou(a1, a2))\n",
    "    # Annotator vs gold\n",
    "    anno1_gold_ious.append(compute_iou(a1, g_all))\n",
    "    anno2_gold_ious.append(compute_iou(a2, g_all))\n",
    "\n",
    "print(f\"\\n In total of {len(data1)} items\")\n",
    "\n",
    "print(f\"\\nAnnotator1 vs Annotator2 IoU: {np.mean(inter_annotator_ious):.4f}\")\n",
    "print(f\"Annotator1 vs Original IoU:   {np.mean(anno1_gold_ious):.4f}\")\n",
    "print(f\"Annotator2 vs Original IoU:   {np.mean(anno2_gold_ious):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
